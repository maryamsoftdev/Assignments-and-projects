{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: Nabeelah Maryam\n",
        "\n",
        "\n",
        "Roll No: 23I-8201"
      ],
      "metadata": {
        "id": "uVLCgVLjWXQW"
      },
      "id": "uVLCgVLjWXQW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependencies:"
      ],
      "metadata": {
        "id": "0jb1nlxCWkwE"
      },
      "id": "0jb1nlxCWkwE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d3bd472",
      "metadata": {
        "id": "9d3bd472"
      },
      "outputs": [],
      "source": [
        "#loading dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "#EDA\n",
        "from collections import Counter\n",
        "# data preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "# data splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "# data modeling\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "#ensembling\n",
        "from mlxtend.classifier import StackingCVClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('heart.csv')\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gX-VQ-Dn8bt",
        "outputId": "defe76ab-fb26-4653-e22b-2288790eb4d1"
      },
      "id": "4gX-VQ-Dn8bt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
            "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
            "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
            "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
            "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
            "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
            "\n",
            "   ca  thal  target  \n",
            "0   0     1       1  \n",
            "1   0     2       1  \n",
            "2   0     2       1  \n",
            "3   0     2       1  \n",
            "4   0     2       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d749194c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d749194c",
        "outputId": "7527b1f8-f4c9-4f16-d8a3-08f808312f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ff2cd7",
      "metadata": {
        "id": "81ff2cd7"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c80644e",
      "metadata": {
        "id": "3c80644e"
      },
      "source": [
        "# Technique 1 Correlation, Polynomial Variance and PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d66684bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d66684bb",
        "outputId": "c9861471-63cd-4b72-ac49-06bd1c2bfdf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target      1.000000\n",
            "exang       0.436757\n",
            "cp          0.433798\n",
            "oldpeak     0.430696\n",
            "thalach     0.421741\n",
            "ca          0.391724\n",
            "slope       0.345877\n",
            "thal        0.344029\n",
            "sex         0.280937\n",
            "age         0.225439\n",
            "trestbps    0.144931\n",
            "restecg     0.137230\n",
            "chol        0.085239\n",
            "fbs         0.028046\n",
            "Name: target, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Calculate correlation matrix and sort by correlation with 'target'\n",
        "correlation_matrix = df.corr().abs()\n",
        "print(correlation_matrix['target'].sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54776d1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54776d1e",
        "outputId": "61ba5695-fc2c-45bf-89fc-b0e2af543559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original number of features: 13\n",
            "Number of features after polynomial transformation: 104\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# Create polynomial features\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_poly = poly.fit_transform(X_normalized)\n",
        "\n",
        "print(\"Original number of features:\", X_normalized.shape[1])\n",
        "print(\"Number of features after polynomial transformation:\", X_poly.shape[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea71b1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ea71b1a",
        "outputId": "848d8d8e-3792-4131-cbd3-3813a628bdf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features after PCA: 68\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Fit PCA on polynomial features\n",
        "# Let's choose to keep 95% of the variance\n",
        "pca = PCA(n_components=0.95)\n",
        "X_pca = pca.fit_transform(X_poly)\n",
        "\n",
        "print(\"Number of features after PCA:\", X_pca.shape[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e484bc82",
      "metadata": {
        "id": "e484bc82"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming X_pca and y are defined and prepared\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb4454c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb4454c6",
        "outputId": "5cf1dea8-f515-49bf-8a8b-65eb2a9e6507"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define a custom weight initializer\n",
        "initializer = tf.keras.initializers.RandomNormal(mean=0., stddev=1.)\n",
        "\n",
        "# Create model\n",
        "model = Sequential([\n",
        "    Dense(12, input_dim=X_train.shape[1], activation='sigmoid', kernel_initializer=initializer),\n",
        "    Dense(8, activation='sigmoid', kernel_initializer=initializer),\n",
        "    Dense(8, activation='sigmoid', kernel_initializer=initializer),\n",
        "    Dense(4, activation='sigmoid', kernel_initializer=initializer),\n",
        "    Dense(4, activation='sigmoid', kernel_initializer=initializer),\n",
        "    Dense(1, activation='sigmoid', kernel_initializer=initializer)\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c004d4ec",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c004d4ec",
        "outputId": "d9a744a5-26f5-443f-cb40-a4d4cce1a9c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.7004 - accuracy: 0.5440 - val_loss: 0.6893 - val_accuracy: 0.5714\n",
            "Epoch 2/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6963 - accuracy: 0.5440 - val_loss: 0.6879 - val_accuracy: 0.5714\n",
            "Epoch 3/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.5440 - val_loss: 0.6880 - val_accuracy: 0.5714\n",
            "Epoch 4/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.5440 - val_loss: 0.6890 - val_accuracy: 0.5714\n",
            "Epoch 5/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.5440 - val_loss: 0.6888 - val_accuracy: 0.5714\n",
            "Epoch 6/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5440 - val_loss: 0.6881 - val_accuracy: 0.5714\n",
            "Epoch 7/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6927 - accuracy: 0.5440 - val_loss: 0.6877 - val_accuracy: 0.5714\n",
            "Epoch 8/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6924 - accuracy: 0.5440 - val_loss: 0.6882 - val_accuracy: 0.5714\n",
            "Epoch 9/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6920 - accuracy: 0.5440 - val_loss: 0.6883 - val_accuracy: 0.5714\n",
            "Epoch 10/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6920 - accuracy: 0.5440 - val_loss: 0.6878 - val_accuracy: 0.5714\n",
            "Epoch 11/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6918 - accuracy: 0.5440 - val_loss: 0.6878 - val_accuracy: 0.5714\n",
            "Epoch 12/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6920 - accuracy: 0.5440 - val_loss: 0.6881 - val_accuracy: 0.5714\n",
            "Epoch 13/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.5440 - val_loss: 0.6878 - val_accuracy: 0.5714\n",
            "Epoch 14/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6916 - accuracy: 0.5440 - val_loss: 0.6872 - val_accuracy: 0.5714\n",
            "Epoch 15/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6921 - accuracy: 0.5440 - val_loss: 0.6875 - val_accuracy: 0.5714\n",
            "Epoch 16/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6915 - accuracy: 0.5440 - val_loss: 0.6873 - val_accuracy: 0.5714\n",
            "Epoch 17/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6912 - accuracy: 0.5440 - val_loss: 0.6870 - val_accuracy: 0.5714\n",
            "Epoch 18/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.5440 - val_loss: 0.6868 - val_accuracy: 0.5714\n",
            "Epoch 19/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6914 - accuracy: 0.5440 - val_loss: 0.6872 - val_accuracy: 0.5714\n",
            "Epoch 20/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6911 - accuracy: 0.5440 - val_loss: 0.6869 - val_accuracy: 0.5714\n",
            "Epoch 21/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.5440 - val_loss: 0.6867 - val_accuracy: 0.5714\n",
            "Epoch 22/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.5440 - val_loss: 0.6869 - val_accuracy: 0.5714\n",
            "Epoch 23/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.5440 - val_loss: 0.6868 - val_accuracy: 0.5714\n",
            "Epoch 24/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.5440 - val_loss: 0.6866 - val_accuracy: 0.5714\n",
            "Epoch 25/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5440 - val_loss: 0.6862 - val_accuracy: 0.5714\n",
            "Epoch 26/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.5440 - val_loss: 0.6864 - val_accuracy: 0.5714\n",
            "Epoch 27/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6917 - accuracy: 0.5440 - val_loss: 0.6870 - val_accuracy: 0.5714\n",
            "Epoch 28/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6911 - accuracy: 0.5440 - val_loss: 0.6863 - val_accuracy: 0.5714\n",
            "Epoch 29/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6908 - accuracy: 0.5440 - val_loss: 0.6861 - val_accuracy: 0.5714\n",
            "Epoch 30/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.5440 - val_loss: 0.6865 - val_accuracy: 0.5714\n",
            "Epoch 31/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5440 - val_loss: 0.6866 - val_accuracy: 0.5714\n",
            "Epoch 32/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.5440 - val_loss: 0.6863 - val_accuracy: 0.5714\n",
            "Epoch 33/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.5440 - val_loss: 0.6865 - val_accuracy: 0.5714\n",
            "Epoch 34/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.5440 - val_loss: 0.6864 - val_accuracy: 0.5714\n",
            "Epoch 35/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6906 - accuracy: 0.5440 - val_loss: 0.6864 - val_accuracy: 0.5714\n",
            "Epoch 36/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.5440 - val_loss: 0.6865 - val_accuracy: 0.5714\n",
            "Epoch 37/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.5440 - val_loss: 0.6861 - val_accuracy: 0.5714\n",
            "Epoch 38/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.5440 - val_loss: 0.6861 - val_accuracy: 0.5714\n",
            "Epoch 39/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5440 - val_loss: 0.6866 - val_accuracy: 0.5714\n",
            "Epoch 40/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6905 - accuracy: 0.5440 - val_loss: 0.6867 - val_accuracy: 0.5714\n",
            "Epoch 41/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5440 - val_loss: 0.6869 - val_accuracy: 0.5714\n",
            "Epoch 42/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6906 - accuracy: 0.5440 - val_loss: 0.6866 - val_accuracy: 0.5714\n",
            "Epoch 43/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6903 - accuracy: 0.5440 - val_loss: 0.6858 - val_accuracy: 0.5714\n",
            "Epoch 44/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5440 - val_loss: 0.6858 - val_accuracy: 0.5714\n",
            "Epoch 45/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.5440 - val_loss: 0.6856 - val_accuracy: 0.5714\n",
            "Epoch 46/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5440 - val_loss: 0.6858 - val_accuracy: 0.5714\n",
            "Epoch 47/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5440 - val_loss: 0.6859 - val_accuracy: 0.5714\n",
            "Epoch 48/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6904 - accuracy: 0.5440 - val_loss: 0.6855 - val_accuracy: 0.5714\n",
            "Epoch 49/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5440 - val_loss: 0.6857 - val_accuracy: 0.5714\n",
            "Epoch 50/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.5440 - val_loss: 0.6857 - val_accuracy: 0.5714\n",
            "Epoch 51/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.5440 - val_loss: 0.6854 - val_accuracy: 0.5714\n",
            "Epoch 52/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6900 - accuracy: 0.5440 - val_loss: 0.6854 - val_accuracy: 0.5714\n",
            "Epoch 53/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6901 - accuracy: 0.5440 - val_loss: 0.6858 - val_accuracy: 0.5714\n",
            "Epoch 54/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6903 - accuracy: 0.5440 - val_loss: 0.6860 - val_accuracy: 0.5714\n",
            "Epoch 55/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.5440 - val_loss: 0.6861 - val_accuracy: 0.5714\n",
            "Epoch 56/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5440 - val_loss: 0.6860 - val_accuracy: 0.5714\n",
            "Epoch 57/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.5440 - val_loss: 0.6860 - val_accuracy: 0.5714\n",
            "Epoch 58/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.5440 - val_loss: 0.6859 - val_accuracy: 0.5714\n",
            "Epoch 59/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6902 - accuracy: 0.5440 - val_loss: 0.6858 - val_accuracy: 0.5714\n",
            "Epoch 60/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6905 - accuracy: 0.5440 - val_loss: 0.6861 - val_accuracy: 0.5714\n",
            "Epoch 61/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 62/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 63/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 64/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 65/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 66/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.5440 - val_loss: 0.6857 - val_accuracy: 0.5714\n",
            "Epoch 67/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.5440 - val_loss: 0.6852 - val_accuracy: 0.5714\n",
            "Epoch 68/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.5440 - val_loss: 0.6854 - val_accuracy: 0.5714\n",
            "Epoch 69/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.5440 - val_loss: 0.6853 - val_accuracy: 0.5714\n",
            "Epoch 70/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6902 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 71/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6898 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 72/150\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6898 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 73/150\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6898 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 74/150\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6898 - accuracy: 0.5440 - val_loss: 0.6852 - val_accuracy: 0.5714\n",
            "Epoch 75/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6898 - accuracy: 0.5440 - val_loss: 0.6852 - val_accuracy: 0.5714\n",
            "Epoch 76/150\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6898 - accuracy: 0.5440 - val_loss: 0.6852 - val_accuracy: 0.5714\n",
            "Epoch 77/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6909 - accuracy: 0.5440 - val_loss: 0.6858 - val_accuracy: 0.5714\n",
            "Epoch 78/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6897 - accuracy: 0.5440 - val_loss: 0.6854 - val_accuracy: 0.5714\n",
            "Epoch 79/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6897 - accuracy: 0.5440 - val_loss: 0.6850 - val_accuracy: 0.5714\n",
            "Epoch 80/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.5440 - val_loss: 0.6852 - val_accuracy: 0.5714\n",
            "Epoch 81/150\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6899 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 82/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 83/150\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6898 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 84/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6900 - accuracy: 0.5440 - val_loss: 0.6855 - val_accuracy: 0.5714\n",
            "Epoch 85/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6897 - accuracy: 0.5440 - val_loss: 0.6854 - val_accuracy: 0.5714\n",
            "Epoch 86/150\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6903 - accuracy: 0.5440 - val_loss: 0.6859 - val_accuracy: 0.5714\n",
            "Epoch 87/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6898 - accuracy: 0.5440 - val_loss: 0.6853 - val_accuracy: 0.5714\n",
            "Epoch 88/150\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6898 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 89/150\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 90/150\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6847 - val_accuracy: 0.5714\n",
            "Epoch 91/150\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 92/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 93/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 94/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6851 - val_accuracy: 0.5714\n",
            "Epoch 95/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6855 - val_accuracy: 0.5714\n",
            "Epoch 96/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6854 - val_accuracy: 0.5714\n",
            "Epoch 97/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6897 - accuracy: 0.5440 - val_loss: 0.6855 - val_accuracy: 0.5714\n",
            "Epoch 98/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6853 - val_accuracy: 0.5714\n",
            "Epoch 99/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6852 - val_accuracy: 0.5714\n",
            "Epoch 100/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6846 - val_accuracy: 0.5714\n",
            "Epoch 101/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6849 - val_accuracy: 0.5714\n",
            "Epoch 102/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6847 - val_accuracy: 0.5714\n",
            "Epoch 103/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6845 - val_accuracy: 0.5714\n",
            "Epoch 104/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6846 - val_accuracy: 0.5714\n",
            "Epoch 105/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 106/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6845 - val_accuracy: 0.5714\n",
            "Epoch 107/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6843 - val_accuracy: 0.5714\n",
            "Epoch 108/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6845 - val_accuracy: 0.5714\n",
            "Epoch 109/150\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6844 - val_accuracy: 0.5714\n",
            "Epoch 110/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6899 - accuracy: 0.5440 - val_loss: 0.6842 - val_accuracy: 0.5714\n",
            "Epoch 111/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.5440 - val_loss: 0.6845 - val_accuracy: 0.5714\n",
            "Epoch 112/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6847 - val_accuracy: 0.5714\n",
            "Epoch 113/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6846 - val_accuracy: 0.5714\n",
            "Epoch 114/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.5440 - val_loss: 0.6846 - val_accuracy: 0.5714\n",
            "Epoch 115/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6846 - val_accuracy: 0.5714\n",
            "Epoch 116/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6841 - val_accuracy: 0.5714\n",
            "Epoch 117/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.5440 - val_loss: 0.6840 - val_accuracy: 0.5714\n",
            "Epoch 118/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6842 - val_accuracy: 0.5714\n",
            "Epoch 119/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.5440 - val_loss: 0.6839 - val_accuracy: 0.5714\n",
            "Epoch 120/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6839 - val_accuracy: 0.5714\n",
            "Epoch 121/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.5440 - val_loss: 0.6841 - val_accuracy: 0.5714\n",
            "Epoch 122/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6845 - val_accuracy: 0.5714\n",
            "Epoch 123/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.5440 - val_loss: 0.6845 - val_accuracy: 0.5714\n",
            "Epoch 124/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 125/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6893 - accuracy: 0.5440 - val_loss: 0.6846 - val_accuracy: 0.5714\n",
            "Epoch 126/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 127/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6846 - val_accuracy: 0.5714\n",
            "Epoch 128/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6845 - val_accuracy: 0.5714\n",
            "Epoch 129/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6895 - accuracy: 0.5440 - val_loss: 0.6849 - val_accuracy: 0.5714\n",
            "Epoch 130/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6893 - accuracy: 0.5440 - val_loss: 0.6846 - val_accuracy: 0.5714\n",
            "Epoch 131/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.5440 - val_loss: 0.6847 - val_accuracy: 0.5714\n",
            "Epoch 132/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.5440 - val_loss: 0.6845 - val_accuracy: 0.5714\n",
            "Epoch 133/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 134/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 135/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 136/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 137/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6893 - accuracy: 0.5440 - val_loss: 0.6848 - val_accuracy: 0.5714\n",
            "Epoch 138/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.5440 - val_loss: 0.6845 - val_accuracy: 0.5714\n",
            "Epoch 139/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6891 - accuracy: 0.5440 - val_loss: 0.6846 - val_accuracy: 0.5714\n",
            "Epoch 140/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.5440 - val_loss: 0.6844 - val_accuracy: 0.5714\n",
            "Epoch 141/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.5440 - val_loss: 0.6846 - val_accuracy: 0.5714\n",
            "Epoch 142/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6891 - accuracy: 0.5440 - val_loss: 0.6844 - val_accuracy: 0.5714\n",
            "Epoch 143/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5440 - val_loss: 0.6845 - val_accuracy: 0.5714\n",
            "Epoch 144/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.5440 - val_loss: 0.6846 - val_accuracy: 0.5714\n",
            "Epoch 145/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6892 - accuracy: 0.5440 - val_loss: 0.6843 - val_accuracy: 0.5714\n",
            "Epoch 146/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.5440 - val_loss: 0.6843 - val_accuracy: 0.5714\n",
            "Epoch 147/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.5440 - val_loss: 0.6842 - val_accuracy: 0.5714\n",
            "Epoch 148/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6890 - accuracy: 0.5440 - val_loss: 0.6842 - val_accuracy: 0.5714\n",
            "Epoch 149/150\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6891 - accuracy: 0.5440 - val_loss: 0.6839 - val_accuracy: 0.5714\n",
            "Epoch 150/150\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6888 - accuracy: 0.5440 - val_loss: 0.6840 - val_accuracy: 0.5714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x796d4d38ace0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=150, batch_size=10, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8661e57",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8661e57",
        "outputId": "75613ad0-4010-4e21-9af7-db4d13369782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6921 - accuracy: 0.5246\n",
            "Accuracy: 52.46%\n"
          ]
        }
      ],
      "source": [
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d70077bd",
      "metadata": {
        "id": "d70077bd"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52a0df49",
      "metadata": {
        "id": "52a0df49"
      },
      "source": [
        "# Technique 2 Infomation gain with Decision tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a788376",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a788376",
        "outputId": "a24476a2-a8c8-4412-c147-e808ed3b209f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Assuming X_train and y_train are already defined and preprocessed\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = dt_classifier.feature_importances_\n",
        "\n",
        "len(feature_importances)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d91a704",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d91a704",
        "outputId": "8d429804-d75f-4729-c1db-0ea973351c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Feature  Importance\n",
            "2         cp    0.225263\n",
            "11        ca    0.118478\n",
            "9    oldpeak    0.113268\n",
            "0        age    0.106735\n",
            "4       chol    0.093679\n",
            "3   trestbps    0.081394\n",
            "8      exang    0.075421\n",
            "7    thalach    0.046207\n",
            "1        sex    0.041015\n",
            "10     slope    0.038537\n",
            "12      thal    0.027214\n",
            "5        fbs    0.016693\n",
            "6    restecg    0.016097\n"
          ]
        }
      ],
      "source": [
        "# Assuming the original dataset columns are in X.columns\n",
        "features = X.columns\n",
        "len(features)\n",
        "importances_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
        "\n",
        "# # Sort the dataframe by importance\n",
        "importances_df = importances_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(importances_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b68062e",
      "metadata": {
        "id": "7b68062e"
      },
      "outputs": [],
      "source": [
        "# Example: Selecting features with importance greater than a threshold (e.g., 0.01)\n",
        "selected_features = importances_df[importances_df['Importance'] > 0.01]['Feature']\n",
        "\n",
        "# Use only the selected features for training\n",
        "X_selected = X[selected_features]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7d9a7fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "c7d9a7fc",
        "outputId": "75c2394a-ad46-490d-9b47-42b8ddbb1650"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     cp  ca  oldpeak  age  chol  trestbps  exang  thalach  sex  slope  thal  \\\n",
              "0     3   0      2.3   63   233       145      0      150    1      0     1   \n",
              "1     2   0      3.5   37   250       130      0      187    1      0     2   \n",
              "2     1   0      1.4   41   204       130      0      172    0      2     2   \n",
              "3     1   0      0.8   56   236       120      0      178    1      2     2   \n",
              "4     0   0      0.6   57   354       120      1      163    0      2     2   \n",
              "..   ..  ..      ...  ...   ...       ...    ...      ...  ...    ...   ...   \n",
              "298   0   0      0.2   57   241       140      1      123    0      1     3   \n",
              "299   3   0      1.2   45   264       110      0      132    1      1     3   \n",
              "300   0   2      3.4   68   193       144      0      141    1      1     3   \n",
              "301   0   1      1.2   57   131       130      1      115    1      1     3   \n",
              "302   1   1      0.0   57   236       130      0      174    0      1     2   \n",
              "\n",
              "     fbs  restecg  \n",
              "0      1        0  \n",
              "1      0        1  \n",
              "2      0        0  \n",
              "3      0        1  \n",
              "4      0        1  \n",
              "..   ...      ...  \n",
              "298    0        1  \n",
              "299    0        1  \n",
              "300    1        1  \n",
              "301    0        1  \n",
              "302    0        0  \n",
              "\n",
              "[303 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3556ebf2-b075-4437-b9b5-3d13d63b27f0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cp</th>\n",
              "      <th>ca</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>age</th>\n",
              "      <th>chol</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>exang</th>\n",
              "      <th>thalach</th>\n",
              "      <th>sex</th>\n",
              "      <th>slope</th>\n",
              "      <th>thal</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>63</td>\n",
              "      <td>233</td>\n",
              "      <td>145</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>37</td>\n",
              "      <td>250</td>\n",
              "      <td>130</td>\n",
              "      <td>0</td>\n",
              "      <td>187</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>41</td>\n",
              "      <td>204</td>\n",
              "      <td>130</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>56</td>\n",
              "      <td>236</td>\n",
              "      <td>120</td>\n",
              "      <td>0</td>\n",
              "      <td>178</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>57</td>\n",
              "      <td>354</td>\n",
              "      <td>120</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>57</td>\n",
              "      <td>241</td>\n",
              "      <td>140</td>\n",
              "      <td>1</td>\n",
              "      <td>123</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>45</td>\n",
              "      <td>264</td>\n",
              "      <td>110</td>\n",
              "      <td>0</td>\n",
              "      <td>132</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>68</td>\n",
              "      <td>193</td>\n",
              "      <td>144</td>\n",
              "      <td>0</td>\n",
              "      <td>141</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>57</td>\n",
              "      <td>131</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>115</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57</td>\n",
              "      <td>236</td>\n",
              "      <td>130</td>\n",
              "      <td>0</td>\n",
              "      <td>174</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3556ebf2-b075-4437-b9b5-3d13d63b27f0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3556ebf2-b075-4437-b9b5-3d13d63b27f0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3556ebf2-b075-4437-b9b5-3d13d63b27f0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2ca9d227-dc1a-4349-913c-6831b18b605c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ca9d227-dc1a-4349-913c-6831b18b605c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2ca9d227-dc1a-4349-913c-6831b18b605c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_selected",
              "summary": "{\n  \"name\": \"X_selected\",\n  \"rows\": 303,\n  \"fields\": [\n    {\n      \"column\": \"cp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldpeak\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1610750220686348,\n        \"min\": 0.0,\n        \"max\": 6.2,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          1.9,\n          3.0,\n          1.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 29,\n        \"max\": 77,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          46,\n          66,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 51,\n        \"min\": 126,\n        \"max\": 564,\n        \"num_unique_values\": 152,\n        \"samples\": [\n          277,\n          169,\n          242\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trestbps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17,\n        \"min\": 94,\n        \"max\": 200,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          104,\n          123,\n          114\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exang\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thalach\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 71,\n        \"max\": 202,\n        \"num_unique_values\": 91,\n        \"samples\": [\n          159,\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"slope\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"thal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fbs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"restecg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X_selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20448a2d",
      "metadata": {
        "id": "20448a2d"
      },
      "outputs": [],
      "source": [
        "# Assuming 'selected_features' is a list of your selected feature names\n",
        "X_train_selected = X_train[selected_features]\n",
        "X_test_selected = X_test[selected_features]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e6e2d79",
      "metadata": {
        "id": "3e6e2d79"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Define a custom initializer\n",
        "class CustomInitializer(tf.keras.initializers.Initializer):\n",
        "    def __init__(self, mean=0., stddev=1.):\n",
        "        self.mean = mean\n",
        "        self.stddev = stddev\n",
        "\n",
        "    def __call__(self, shape, dtype=None):\n",
        "        return tf.random.normal(shape, mean=self.mean, stddev=self.stddev)\n",
        "\n",
        "# Create the model with five hidden layers\n",
        "model2 = Sequential([\n",
        "    Dense(12, input_shape=(X_train_selected.shape[1],), activation='sigmoid', kernel_initializer=CustomInitializer()),\n",
        "    Dense(10, activation='sigmoid', kernel_initializer=CustomInitializer()),\n",
        "    Dense(8, activation='sigmoid', kernel_initializer=CustomInitializer()),\n",
        "    Dense(6, activation='sigmoid', kernel_initializer=CustomInitializer()),\n",
        "    Dense(4, activation='sigmoid', kernel_initializer=CustomInitializer()),\n",
        "    Dense(1, activation='sigmoid', kernel_initializer=CustomInitializer())\n",
        "])\n",
        "\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ea83146",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ea83146",
        "outputId": "4f9af178-86ed-4e82-96e2-35bfd0bb42a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "20/20 [==============================] - 3s 25ms/step - loss: 0.7020 - accuracy: 0.5440 - val_loss: 0.6859 - val_accuracy: 0.5714\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6976 - accuracy: 0.5440 - val_loss: 0.6839 - val_accuracy: 0.5714\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6945 - accuracy: 0.5440 - val_loss: 0.6826 - val_accuracy: 0.5714\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.5440 - val_loss: 0.6815 - val_accuracy: 0.5714\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6908 - accuracy: 0.5440 - val_loss: 0.6807 - val_accuracy: 0.5714\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6896 - accuracy: 0.5440 - val_loss: 0.6800 - val_accuracy: 0.5714\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6885 - accuracy: 0.5440 - val_loss: 0.6795 - val_accuracy: 0.5714\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5440 - val_loss: 0.6792 - val_accuracy: 0.5714\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6870 - accuracy: 0.5440 - val_loss: 0.6788 - val_accuracy: 0.5714\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6867 - accuracy: 0.5440 - val_loss: 0.6782 - val_accuracy: 0.5714\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.5440 - val_loss: 0.6779 - val_accuracy: 0.5714\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5440 - val_loss: 0.6775 - val_accuracy: 0.5714\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.5440 - val_loss: 0.6769 - val_accuracy: 0.5714\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.5440 - val_loss: 0.6769 - val_accuracy: 0.5714\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6844 - accuracy: 0.5440 - val_loss: 0.6764 - val_accuracy: 0.5714\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.5440 - val_loss: 0.6763 - val_accuracy: 0.5714\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6835 - accuracy: 0.5440 - val_loss: 0.6756 - val_accuracy: 0.5714\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6829 - accuracy: 0.5440 - val_loss: 0.6751 - val_accuracy: 0.5714\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6827 - accuracy: 0.5440 - val_loss: 0.6744 - val_accuracy: 0.5714\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.5440 - val_loss: 0.6741 - val_accuracy: 0.5714\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6816 - accuracy: 0.5440 - val_loss: 0.6730 - val_accuracy: 0.5714\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6815 - accuracy: 0.5440 - val_loss: 0.6721 - val_accuracy: 0.5714\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6805 - accuracy: 0.5440 - val_loss: 0.6717 - val_accuracy: 0.5714\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6799 - accuracy: 0.5440 - val_loss: 0.6713 - val_accuracy: 0.5714\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6796 - accuracy: 0.5440 - val_loss: 0.6703 - val_accuracy: 0.5714\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6788 - accuracy: 0.5440 - val_loss: 0.6697 - val_accuracy: 0.5714\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6784 - accuracy: 0.5440 - val_loss: 0.6689 - val_accuracy: 0.5714\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.5440 - val_loss: 0.6683 - val_accuracy: 0.5714\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6771 - accuracy: 0.5440 - val_loss: 0.6675 - val_accuracy: 0.5714\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.5440 - val_loss: 0.6665 - val_accuracy: 0.5714\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.5440 - val_loss: 0.6655 - val_accuracy: 0.5714\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6753 - accuracy: 0.5440 - val_loss: 0.6646 - val_accuracy: 0.5714\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6744 - accuracy: 0.5440 - val_loss: 0.6642 - val_accuracy: 0.5714\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6737 - accuracy: 0.5440 - val_loss: 0.6630 - val_accuracy: 0.5714\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6733 - accuracy: 0.5440 - val_loss: 0.6621 - val_accuracy: 0.5714\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6727 - accuracy: 0.5440 - val_loss: 0.6609 - val_accuracy: 0.5714\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6718 - accuracy: 0.5440 - val_loss: 0.6606 - val_accuracy: 0.5714\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6717 - accuracy: 0.5440 - val_loss: 0.6591 - val_accuracy: 0.5714\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6709 - accuracy: 0.5440 - val_loss: 0.6581 - val_accuracy: 0.5714\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6695 - accuracy: 0.5440 - val_loss: 0.6577 - val_accuracy: 0.5714\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6689 - accuracy: 0.5440 - val_loss: 0.6557 - val_accuracy: 0.5714\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.5440 - val_loss: 0.6547 - val_accuracy: 0.5714\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6673 - accuracy: 0.5440 - val_loss: 0.6538 - val_accuracy: 0.5714\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.5440 - val_loss: 0.6526 - val_accuracy: 0.5714\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6653 - accuracy: 0.5440 - val_loss: 0.6522 - val_accuracy: 0.5714\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6679 - accuracy: 0.5440 - val_loss: 0.6521 - val_accuracy: 0.5714\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6645 - accuracy: 0.5440 - val_loss: 0.6489 - val_accuracy: 0.5714\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6640 - accuracy: 0.5440 - val_loss: 0.6468 - val_accuracy: 0.5714\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6624 - accuracy: 0.5440 - val_loss: 0.6455 - val_accuracy: 0.5714\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6621 - accuracy: 0.5337 - val_loss: 0.6460 - val_accuracy: 0.5714\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6608 - accuracy: 0.5440 - val_loss: 0.6453 - val_accuracy: 0.5714\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.5492 - val_loss: 0.6442 - val_accuracy: 0.5510\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6594 - accuracy: 0.5544 - val_loss: 0.6417 - val_accuracy: 0.5918\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6588 - accuracy: 0.5648 - val_loss: 0.6394 - val_accuracy: 0.6327\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6588 - accuracy: 0.5907 - val_loss: 0.6419 - val_accuracy: 0.6327\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6580 - accuracy: 0.5959 - val_loss: 0.6408 - val_accuracy: 0.6327\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6571 - accuracy: 0.5803 - val_loss: 0.6362 - val_accuracy: 0.6735\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6555 - accuracy: 0.6528 - val_loss: 0.6377 - val_accuracy: 0.6735\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6556 - accuracy: 0.6477 - val_loss: 0.6368 - val_accuracy: 0.6735\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6538 - accuracy: 0.6580 - val_loss: 0.6328 - val_accuracy: 0.6939\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6537 - accuracy: 0.6528 - val_loss: 0.6360 - val_accuracy: 0.7143\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6537 - accuracy: 0.6528 - val_loss: 0.6327 - val_accuracy: 0.6939\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6519 - accuracy: 0.6477 - val_loss: 0.6339 - val_accuracy: 0.6939\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.6510 - accuracy: 0.6528 - val_loss: 0.6322 - val_accuracy: 0.6939\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.6511 - accuracy: 0.6528 - val_loss: 0.6315 - val_accuracy: 0.6939\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 1s 25ms/step - loss: 0.6503 - accuracy: 0.6580 - val_loss: 0.6306 - val_accuracy: 0.6939\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 0s 25ms/step - loss: 0.6498 - accuracy: 0.6425 - val_loss: 0.6267 - val_accuracy: 0.6939\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 0s 21ms/step - loss: 0.6505 - accuracy: 0.6632 - val_loss: 0.6245 - val_accuracy: 0.7143\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.6495 - accuracy: 0.6528 - val_loss: 0.6302 - val_accuracy: 0.6939\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.6492 - accuracy: 0.6580 - val_loss: 0.6287 - val_accuracy: 0.6939\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.6483 - accuracy: 0.6528 - val_loss: 0.6259 - val_accuracy: 0.6939\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6462 - accuracy: 0.6580 - val_loss: 0.6270 - val_accuracy: 0.6939\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.6457 - accuracy: 0.6684 - val_loss: 0.6231 - val_accuracy: 0.6939\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6453 - accuracy: 0.6632 - val_loss: 0.6269 - val_accuracy: 0.6939\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6441 - accuracy: 0.6528 - val_loss: 0.6236 - val_accuracy: 0.6939\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6438 - accuracy: 0.6684 - val_loss: 0.6233 - val_accuracy: 0.6939\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6459 - accuracy: 0.6580 - val_loss: 0.6243 - val_accuracy: 0.6939\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6528 - val_loss: 0.6229 - val_accuracy: 0.6939\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.6442 - accuracy: 0.6632 - val_loss: 0.6232 - val_accuracy: 0.6939\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6425 - accuracy: 0.6580 - val_loss: 0.6226 - val_accuracy: 0.6939\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6441 - accuracy: 0.6632 - val_loss: 0.6155 - val_accuracy: 0.6939\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.6402 - accuracy: 0.6684 - val_loss: 0.6212 - val_accuracy: 0.6939\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.6632 - val_loss: 0.6222 - val_accuracy: 0.6939\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6439 - accuracy: 0.6580 - val_loss: 0.6195 - val_accuracy: 0.6939\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.6416 - accuracy: 0.6580 - val_loss: 0.6203 - val_accuracy: 0.6939\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6377 - accuracy: 0.6632 - val_loss: 0.6174 - val_accuracy: 0.6939\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6381 - accuracy: 0.6632 - val_loss: 0.6191 - val_accuracy: 0.6939\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6416 - accuracy: 0.6528 - val_loss: 0.6233 - val_accuracy: 0.6735\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.6396 - accuracy: 0.6684 - val_loss: 0.6181 - val_accuracy: 0.6939\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.6363 - accuracy: 0.6684 - val_loss: 0.6173 - val_accuracy: 0.6939\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.6362 - accuracy: 0.6684 - val_loss: 0.6125 - val_accuracy: 0.7143\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.6373 - accuracy: 0.6684 - val_loss: 0.6144 - val_accuracy: 0.6939\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.6376 - accuracy: 0.6580 - val_loss: 0.6148 - val_accuracy: 0.6939\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.6339 - accuracy: 0.6632 - val_loss: 0.6138 - val_accuracy: 0.6939\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.6338 - accuracy: 0.6684 - val_loss: 0.6137 - val_accuracy: 0.6939\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.6318 - accuracy: 0.6788 - val_loss: 0.6137 - val_accuracy: 0.6939\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.6324 - accuracy: 0.6736 - val_loss: 0.6129 - val_accuracy: 0.6939\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.6331 - accuracy: 0.6736 - val_loss: 0.6151 - val_accuracy: 0.6939\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.6316 - accuracy: 0.6684 - val_loss: 0.6122 - val_accuracy: 0.7143\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.6305 - accuracy: 0.6736 - val_loss: 0.6128 - val_accuracy: 0.6939\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.6297 - accuracy: 0.6736 - val_loss: 0.6117 - val_accuracy: 0.6939\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.6301 - accuracy: 0.6788 - val_loss: 0.6113 - val_accuracy: 0.6939\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.6327 - accuracy: 0.6580 - val_loss: 0.6078 - val_accuracy: 0.6939\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6298 - accuracy: 0.6684 - val_loss: 0.6100 - val_accuracy: 0.7143\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6287 - accuracy: 0.6788 - val_loss: 0.6101 - val_accuracy: 0.7143\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6271 - accuracy: 0.6788 - val_loss: 0.6095 - val_accuracy: 0.7143\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6273 - accuracy: 0.6788 - val_loss: 0.6088 - val_accuracy: 0.7143\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6271 - accuracy: 0.6788 - val_loss: 0.6088 - val_accuracy: 0.7143\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6269 - accuracy: 0.6736 - val_loss: 0.6084 - val_accuracy: 0.7143\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6257 - accuracy: 0.6788 - val_loss: 0.6080 - val_accuracy: 0.7143\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.6257 - accuracy: 0.6788 - val_loss: 0.6072 - val_accuracy: 0.7143\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 0s 16ms/step - loss: 0.6252 - accuracy: 0.6788 - val_loss: 0.6071 - val_accuracy: 0.7143\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.6302 - accuracy: 0.6632 - val_loss: 0.6065 - val_accuracy: 0.6939\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6264 - accuracy: 0.6736 - val_loss: 0.6094 - val_accuracy: 0.7143\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6257 - accuracy: 0.6736 - val_loss: 0.6073 - val_accuracy: 0.7143\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6248 - accuracy: 0.6736 - val_loss: 0.6066 - val_accuracy: 0.7143\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6238 - accuracy: 0.6788 - val_loss: 0.6062 - val_accuracy: 0.7143\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6244 - accuracy: 0.6736 - val_loss: 0.6053 - val_accuracy: 0.7143\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.6230 - accuracy: 0.6788 - val_loss: 0.6065 - val_accuracy: 0.7143\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6240 - accuracy: 0.6839 - val_loss: 0.6050 - val_accuracy: 0.7143\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6225 - accuracy: 0.6839 - val_loss: 0.6057 - val_accuracy: 0.7143\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6227 - accuracy: 0.6788 - val_loss: 0.6048 - val_accuracy: 0.7143\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6226 - accuracy: 0.6736 - val_loss: 0.6055 - val_accuracy: 0.7143\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6230 - accuracy: 0.6788 - val_loss: 0.6015 - val_accuracy: 0.7143\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.6221 - accuracy: 0.6839 - val_loss: 0.6021 - val_accuracy: 0.7143\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 0s 9ms/step - loss: 0.6215 - accuracy: 0.6788 - val_loss: 0.6018 - val_accuracy: 0.7143\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6219 - accuracy: 0.6891 - val_loss: 0.6002 - val_accuracy: 0.7143\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6198 - accuracy: 0.6839 - val_loss: 0.6010 - val_accuracy: 0.7143\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6215 - accuracy: 0.6788 - val_loss: 0.6012 - val_accuracy: 0.7143\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.6891 - val_loss: 0.5988 - val_accuracy: 0.7143\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.6891 - val_loss: 0.6008 - val_accuracy: 0.7143\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6193 - accuracy: 0.6891 - val_loss: 0.6032 - val_accuracy: 0.7143\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6205 - accuracy: 0.6839 - val_loss: 0.6015 - val_accuracy: 0.7143\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6218 - accuracy: 0.6788 - val_loss: 0.6006 - val_accuracy: 0.7143\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6199 - accuracy: 0.6891 - val_loss: 0.6005 - val_accuracy: 0.7143\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6189 - accuracy: 0.6839 - val_loss: 0.6008 - val_accuracy: 0.7143\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6178 - accuracy: 0.6891 - val_loss: 0.5992 - val_accuracy: 0.7143\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6164 - accuracy: 0.6943 - val_loss: 0.6004 - val_accuracy: 0.7143\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6192 - accuracy: 0.6839 - val_loss: 0.6068 - val_accuracy: 0.6939\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6198 - accuracy: 0.6839 - val_loss: 0.6021 - val_accuracy: 0.7143\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6152 - accuracy: 0.6943 - val_loss: 0.5979 - val_accuracy: 0.7143\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.6891 - val_loss: 0.5992 - val_accuracy: 0.7143\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6160 - accuracy: 0.6943 - val_loss: 0.5998 - val_accuracy: 0.7143\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6159 - accuracy: 0.6891 - val_loss: 0.5984 - val_accuracy: 0.7143\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6164 - accuracy: 0.6891 - val_loss: 0.6007 - val_accuracy: 0.7143\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.6891 - val_loss: 0.5992 - val_accuracy: 0.7143\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6153 - accuracy: 0.6943 - val_loss: 0.5977 - val_accuracy: 0.7143\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6136 - accuracy: 0.6943 - val_loss: 0.5990 - val_accuracy: 0.7143\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6143 - accuracy: 0.6995 - val_loss: 0.6019 - val_accuracy: 0.7143\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6157 - accuracy: 0.6891 - val_loss: 0.5997 - val_accuracy: 0.7143\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6170 - accuracy: 0.6891 - val_loss: 0.6048 - val_accuracy: 0.6939\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6159 - accuracy: 0.6839 - val_loss: 0.5996 - val_accuracy: 0.7143\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.6943 - val_loss: 0.6018 - val_accuracy: 0.7143\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6143 - accuracy: 0.6943 - val_loss: 0.5993 - val_accuracy: 0.7143\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.6995 - val_loss: 0.6007 - val_accuracy: 0.7143\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6124 - accuracy: 0.6943 - val_loss: 0.5997 - val_accuracy: 0.7143\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6117 - accuracy: 0.6995 - val_loss: 0.5989 - val_accuracy: 0.7143\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6112 - accuracy: 0.6995 - val_loss: 0.6013 - val_accuracy: 0.7143\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6150 - accuracy: 0.6943 - val_loss: 0.6006 - val_accuracy: 0.7143\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6123 - accuracy: 0.6943 - val_loss: 0.5988 - val_accuracy: 0.7143\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6123 - accuracy: 0.6943 - val_loss: 0.6002 - val_accuracy: 0.7143\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6112 - accuracy: 0.6891 - val_loss: 0.6011 - val_accuracy: 0.7143\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6117 - accuracy: 0.6943 - val_loss: 0.5978 - val_accuracy: 0.7143\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6104 - accuracy: 0.6943 - val_loss: 0.6008 - val_accuracy: 0.7143\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6102 - accuracy: 0.6995 - val_loss: 0.5979 - val_accuracy: 0.7143\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6108 - accuracy: 0.6943 - val_loss: 0.6045 - val_accuracy: 0.7143\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6131 - accuracy: 0.6943 - val_loss: 0.6001 - val_accuracy: 0.7143\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6105 - accuracy: 0.6995 - val_loss: 0.5994 - val_accuracy: 0.7143\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.6943 - val_loss: 0.6034 - val_accuracy: 0.7143\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6089 - accuracy: 0.6995 - val_loss: 0.5994 - val_accuracy: 0.7143\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6095 - accuracy: 0.6995 - val_loss: 0.6004 - val_accuracy: 0.7143\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6096 - accuracy: 0.6943 - val_loss: 0.6011 - val_accuracy: 0.7143\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.6995 - val_loss: 0.6023 - val_accuracy: 0.7143\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6093 - accuracy: 0.6995 - val_loss: 0.6025 - val_accuracy: 0.7143\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6084 - accuracy: 0.6995 - val_loss: 0.5989 - val_accuracy: 0.7143\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6084 - accuracy: 0.6995 - val_loss: 0.6026 - val_accuracy: 0.7143\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.6943 - val_loss: 0.6030 - val_accuracy: 0.7143\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6090 - accuracy: 0.6995 - val_loss: 0.6033 - val_accuracy: 0.7143\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6077 - accuracy: 0.6995 - val_loss: 0.6013 - val_accuracy: 0.7143\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.6995 - val_loss: 0.5995 - val_accuracy: 0.7143\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6108 - accuracy: 0.6995 - val_loss: 0.6008 - val_accuracy: 0.7143\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.6891 - val_loss: 0.6026 - val_accuracy: 0.7143\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6083 - accuracy: 0.6995 - val_loss: 0.6012 - val_accuracy: 0.7143\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6078 - accuracy: 0.6943 - val_loss: 0.6036 - val_accuracy: 0.7143\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6071 - accuracy: 0.6995 - val_loss: 0.6016 - val_accuracy: 0.7143\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6071 - accuracy: 0.6995 - val_loss: 0.6033 - val_accuracy: 0.7143\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6062 - accuracy: 0.6995 - val_loss: 0.6015 - val_accuracy: 0.7143\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.6995 - val_loss: 0.6027 - val_accuracy: 0.7143\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6995 - val_loss: 0.5996 - val_accuracy: 0.7143\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6085 - accuracy: 0.6891 - val_loss: 0.6048 - val_accuracy: 0.6939\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.6943 - val_loss: 0.6002 - val_accuracy: 0.7143\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.6943 - val_loss: 0.6053 - val_accuracy: 0.6939\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6088 - accuracy: 0.6943 - val_loss: 0.6009 - val_accuracy: 0.7143\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6059 - accuracy: 0.6995 - val_loss: 0.6026 - val_accuracy: 0.7143\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6060 - accuracy: 0.6995 - val_loss: 0.6034 - val_accuracy: 0.7143\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.6943 - val_loss: 0.6003 - val_accuracy: 0.7143\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6090 - accuracy: 0.6943 - val_loss: 0.6024 - val_accuracy: 0.7143\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 0s 5ms/step - loss: 0.6079 - accuracy: 0.6891 - val_loss: 0.6024 - val_accuracy: 0.7143\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6070 - accuracy: 0.6995 - val_loss: 0.6006 - val_accuracy: 0.7143\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.6943 - val_loss: 0.6067 - val_accuracy: 0.6939\n"
          ]
        }
      ],
      "source": [
        "history = model2.fit(X_train_selected, y_train, validation_split=0.2, epochs=200, batch_size=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fddcd8f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fddcd8f0",
        "outputId": "ab3fd5c8-63aa-4287-d545-74998ebc9422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 16ms/step - loss: 0.5515 - accuracy: 0.7541\n",
            "Test Accuracy: 75.41%\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model2.evaluate(X_test_selected, y_test)\n",
        "print(f'Test Accuracy of custom model: {accuracy*100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JRt6r-3Mgutc"
      },
      "id": "JRt6r-3Mgutc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9027bd3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9027bd3",
        "outputId": "34302958-24a8-4628-aa3c-caffa109256e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confussion matrix\n",
            "[[25  4]\n",
            " [ 3 29]]\n",
            "\n",
            "\n",
            "Accuracy of Logistic Regression: 88.52459016393442 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.86      0.88        29\n",
            "           1       0.88      0.91      0.89        32\n",
            "\n",
            "    accuracy                           0.89        61\n",
            "   macro avg       0.89      0.88      0.88        61\n",
            "weighted avg       0.89      0.89      0.89        61\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "m1 = 'Logistic Regression'\n",
        "lr = LogisticRegression()\n",
        "model = lr.fit(X_train, y_train)\n",
        "lr_predict = lr.predict(X_test)\n",
        "lr_conf_matrix = confusion_matrix(y_test, lr_predict)\n",
        "lr_acc_score = accuracy_score(y_test, lr_predict)\n",
        "print(\"confussion matrix\")\n",
        "print(lr_conf_matrix)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy of Logistic Regression:\",lr_acc_score*100,'\\n')\n",
        "print(classification_report(y_test,lr_predict))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m2 = 'Support Vector Classifier'\n",
        "svc =  SVC(kernel='rbf', C=2)\n",
        "svc.fit(X_train, y_train)\n",
        "svc_predicted = svc.predict(X_test)\n",
        "svc_conf_matrix = confusion_matrix(y_test, svc_predicted)\n",
        "svc_acc_score = accuracy_score(y_test, svc_predicted)\n",
        "print(\"confussion matrix\")\n",
        "print(svc_conf_matrix)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy of Support Vector Classifier:\",svc_acc_score*100,'\\n')\n",
        "print(classification_report(y_test,svc_predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtixuhxZgZ3Z",
        "outputId": "17629b5e-c35c-4767-ef0d-48fcc9d383fd"
      },
      "id": "HtixuhxZgZ3Z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confussion matrix\n",
            "[[16 13]\n",
            " [ 5 27]]\n",
            "\n",
            "\n",
            "Accuracy of Support Vector Classifier: 70.49180327868852 \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.55      0.64        29\n",
            "           1       0.68      0.84      0.75        32\n",
            "\n",
            "    accuracy                           0.70        61\n",
            "   macro avg       0.72      0.70      0.70        61\n",
            "weighted avg       0.72      0.70      0.70        61\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1bsvvQBfnJSA"
      },
      "id": "1bsvvQBfnJSA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}