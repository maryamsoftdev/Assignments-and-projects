{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c4d3fa2-54c4-4915-828a-b44fb687a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30de094-5749-49e9-887c-43af854f7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------> Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#------------------> Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "471c9a91-d226-4822-961e-27d4fb77b265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f41699-fcf6-4d73-a39c-3c5acded4cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f02fa562-1432-416c-8083-69b19e8fb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------> Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8d5a080-180a-410a-aa53-c11ae6118b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.38535265e+00,  3.28414053e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.50652052e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.24920112e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-5.37177559e-01,  1.93979142e+00, -1.16971425e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.50652052e+00,  7.88807586e-01, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.02184904e+00,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.74885626e+00, -3.62176246e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-5.37177559e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00,  7.88807586e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-1.87002413e+00, -1.31979479e-01, -1.51073881e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-5.25060772e-02,  2.16998818e+00, -1.45390138e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.73673948e-01,  3.09077525e+00, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-5.37177559e-01,  1.93979142e+00, -1.39706395e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-9.00681170e-01,  1.01900435e+00, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.73673948e-01,  1.70959465e+00, -1.16971425e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.28338910e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-5.37177559e-01,  7.88807586e-01, -1.16971425e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.50652052e+00,  1.24920112e+00, -1.56757623e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  5.58610819e-01, -1.16971425e+00,\n",
       "        -9.20547742e-01],\n",
       "       [-1.26418478e+00,  7.88807586e-01, -1.05603939e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00, -1.31979479e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  7.88807586e-01, -1.22655167e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-7.79513300e-01,  1.01900435e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-7.79513300e-01,  7.88807586e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.38535265e+00,  3.28414053e-01, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.26418478e+00,  9.82172869e-02, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-5.37177559e-01,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-7.79513300e-01,  2.40018495e+00, -1.28338910e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-4.16009689e-01,  2.63038172e+00, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  9.82172869e-02, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  3.28414053e-01, -1.45390138e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-4.16009689e-01,  1.01900435e+00, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.14301691e+00,  1.24920112e+00, -1.34022653e+00,\n",
       "        -1.44707648e+00],\n",
       "       [-1.74885626e+00, -1.31979479e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-9.00681170e-01,  7.88807586e-01, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.01900435e+00, -1.39706395e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.62768839e+00, -1.74335684e+00, -1.39706395e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-1.74885626e+00,  3.28414053e-01, -1.39706395e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  1.01900435e+00, -1.22655167e+00,\n",
       "        -7.88915558e-01],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.05603939e+00,\n",
       "        -1.05217993e+00],\n",
       "       [-1.26418478e+00, -1.31979479e-01, -1.34022653e+00,\n",
       "        -1.18381211e+00],\n",
       "       [-9.00681170e-01,  1.70959465e+00, -1.22655167e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.50652052e+00,  3.28414053e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-6.58345429e-01,  1.47939788e+00, -1.28338910e+00,\n",
       "        -1.31544430e+00],\n",
       "       [-1.02184904e+00,  5.58610819e-01, -1.34022653e+00,\n",
       "        -1.31544430e+00],\n",
       "       [ 1.40150837e+00,  3.28414053e-01,  5.35408562e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 6.74501145e-01,  3.28414053e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  6.49083415e-01,\n",
       "         3.95774101e-01],\n",
       "       [-4.16009689e-01, -1.74335684e+00,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 7.95669016e-01, -5.92373012e-01,  4.78571135e-01,\n",
       "         3.95774101e-01],\n",
       "       [-1.73673948e-01, -5.92373012e-01,  4.21733708e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01,  5.58610819e-01,  5.35408562e-01,\n",
       "         5.27406285e-01],\n",
       "       [-1.14301691e+00, -1.51316008e+00, -2.60315415e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 9.16836886e-01, -3.62176246e-01,  4.78571135e-01,\n",
       "         1.32509732e-01],\n",
       "       [-7.79513300e-01, -8.22569778e-01,  8.07091462e-02,\n",
       "         2.64141916e-01],\n",
       "       [-1.02184904e+00, -2.43394714e+00, -1.46640561e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 6.86617933e-02, -1.31979479e-01,  2.51221427e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.89829664e-01, -1.97355361e+00,  1.37546573e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 3.10997534e-01, -3.62176246e-01,  5.35408562e-01,\n",
       "         2.64141916e-01],\n",
       "       [-2.94841818e-01, -3.62176246e-01, -8.98031345e-02,\n",
       "         1.32509732e-01],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  3.64896281e-01,\n",
       "         2.64141916e-01],\n",
       "       [-2.94841818e-01, -1.31979479e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  1.94384000e-01,\n",
       "        -2.62386821e-01],\n",
       "       [ 4.32165405e-01, -1.97355361e+00,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-2.94841818e-01, -1.28296331e+00,  8.07091462e-02,\n",
       "        -1.30754636e-01],\n",
       "       [ 6.86617933e-02,  3.28414053e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 3.10997534e-01, -5.92373012e-01,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01, -1.28296331e+00,  6.49083415e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 3.10997534e-01, -5.92373012e-01,  5.35408562e-01,\n",
       "         8.77547895e-04],\n",
       "       [ 6.74501145e-01, -3.62176246e-01,  3.08058854e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 9.16836886e-01, -1.31979479e-01,  3.64896281e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 1.15917263e+00, -5.92373012e-01,  5.92245988e-01,\n",
       "         2.64141916e-01],\n",
       "       [ 1.03800476e+00, -1.31979479e-01,  7.05920842e-01,\n",
       "         6.59038469e-01],\n",
       "       [ 1.89829664e-01, -3.62176246e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [-1.73673948e-01, -1.05276654e+00, -1.46640561e-01,\n",
       "        -2.62386821e-01],\n",
       "       [-4.16009689e-01, -1.51316008e+00,  2.38717193e-02,\n",
       "        -1.30754636e-01],\n",
       "       [-4.16009689e-01, -1.51316008e+00, -3.29657076e-02,\n",
       "        -2.62386821e-01],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  8.07091462e-02,\n",
       "         8.77547895e-04],\n",
       "       [ 1.89829664e-01, -8.22569778e-01,  7.62758269e-01,\n",
       "         5.27406285e-01],\n",
       "       [-5.37177559e-01, -1.31979479e-01,  4.21733708e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.89829664e-01,  7.88807586e-01,  4.21733708e-01,\n",
       "         5.27406285e-01],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  5.35408562e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 5.53333275e-01, -1.74335684e+00,  3.64896281e-01,\n",
       "         1.32509732e-01],\n",
       "       [-2.94841818e-01, -1.31979479e-01,  1.94384000e-01,\n",
       "         1.32509732e-01],\n",
       "       [-4.16009689e-01, -1.28296331e+00,  1.37546573e-01,\n",
       "         1.32509732e-01],\n",
       "       [-4.16009689e-01, -1.05276654e+00,  3.64896281e-01,\n",
       "         8.77547895e-04],\n",
       "       [ 3.10997534e-01, -1.31979479e-01,  4.78571135e-01,\n",
       "         2.64141916e-01],\n",
       "       [-5.25060772e-02, -1.05276654e+00,  1.37546573e-01,\n",
       "         8.77547895e-04],\n",
       "       [-1.02184904e+00, -1.74335684e+00, -2.60315415e-01,\n",
       "        -2.62386821e-01],\n",
       "       [-2.94841818e-01, -8.22569778e-01,  2.51221427e-01,\n",
       "         1.32509732e-01],\n",
       "       [-1.73673948e-01, -1.31979479e-01,  2.51221427e-01,\n",
       "         8.77547895e-04],\n",
       "       [-1.73673948e-01, -3.62176246e-01,  2.51221427e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 4.32165405e-01, -3.62176246e-01,  3.08058854e-01,\n",
       "         1.32509732e-01],\n",
       "       [-9.00681170e-01, -1.28296331e+00, -4.30827696e-01,\n",
       "        -1.30754636e-01],\n",
       "       [-1.73673948e-01, -5.92373012e-01,  1.94384000e-01,\n",
       "         1.32509732e-01],\n",
       "       [ 5.53333275e-01,  5.58610819e-01,  1.27429511e+00,\n",
       "         1.71209594e+00],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.52267624e+00, -1.31979479e-01,  1.21745768e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 5.53333275e-01, -3.62176246e-01,  1.04694540e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  1.16062026e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 2.12851559e+00, -1.31979479e-01,  1.61531967e+00,\n",
       "         1.18556721e+00],\n",
       "       [-1.14301691e+00, -1.28296331e+00,  4.21733708e-01,\n",
       "         6.59038469e-01],\n",
       "       [ 1.76501198e+00, -3.62176246e-01,  1.44480739e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 1.03800476e+00, -1.28296331e+00,  1.16062026e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 1.64384411e+00,  1.24920112e+00,  1.33113254e+00,\n",
       "         1.71209594e+00],\n",
       "       [ 7.95669016e-01,  3.28414053e-01,  7.62758269e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 6.74501145e-01, -8.22569778e-01,  8.76433123e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.15917263e+00, -1.31979479e-01,  9.90107977e-01,\n",
       "         1.18556721e+00],\n",
       "       [-1.73673948e-01, -1.28296331e+00,  7.05920842e-01,\n",
       "         1.05393502e+00],\n",
       "       [-5.25060772e-02, -5.92373012e-01,  7.62758269e-01,\n",
       "         1.58046376e+00],\n",
       "       [ 6.74501145e-01,  3.28414053e-01,  8.76433123e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  9.90107977e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 2.24968346e+00,  1.70959465e+00,  1.67215710e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 2.24968346e+00, -1.05276654e+00,  1.78583195e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 1.89829664e-01, -1.97355361e+00,  7.05920842e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 1.28034050e+00,  3.28414053e-01,  1.10378283e+00,\n",
       "         1.44883158e+00],\n",
       "       [-2.94841818e-01, -5.92373012e-01,  6.49083415e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 2.24968346e+00, -5.92373012e-01,  1.67215710e+00,\n",
       "         1.05393502e+00],\n",
       "       [ 5.53333275e-01, -8.22569778e-01,  6.49083415e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 1.64384411e+00,  3.28414053e-01,  1.27429511e+00,\n",
       "         7.90670654e-01],\n",
       "       [ 4.32165405e-01, -5.92373012e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 3.10997534e-01, -1.31979479e-01,  6.49083415e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
       "         1.18556721e+00],\n",
       "       [ 1.64384411e+00, -1.31979479e-01,  1.16062026e+00,\n",
       "         5.27406285e-01],\n",
       "       [ 1.88617985e+00, -5.92373012e-01,  1.33113254e+00,\n",
       "         9.22302838e-01],\n",
       "       [ 2.49201920e+00,  1.70959465e+00,  1.50164482e+00,\n",
       "         1.05393502e+00],\n",
       "       [ 6.74501145e-01, -5.92373012e-01,  1.04694540e+00,\n",
       "         1.31719939e+00],\n",
       "       [ 5.53333275e-01, -5.92373012e-01,  7.62758269e-01,\n",
       "         3.95774101e-01],\n",
       "       [ 3.10997534e-01, -1.05276654e+00,  1.04694540e+00,\n",
       "         2.64141916e-01],\n",
       "       [ 2.24968346e+00, -1.31979479e-01,  1.33113254e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 5.53333275e-01,  7.88807586e-01,  1.04694540e+00,\n",
       "         1.58046376e+00],\n",
       "       [ 6.74501145e-01,  9.82172869e-02,  9.90107977e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.89829664e-01, -1.31979479e-01,  5.92245988e-01,\n",
       "         7.90670654e-01],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  9.33270550e-01,\n",
       "         1.18556721e+00],\n",
       "       [ 1.03800476e+00,  9.82172869e-02,  1.04694540e+00,\n",
       "         1.58046376e+00],\n",
       "       [ 1.28034050e+00,  9.82172869e-02,  7.62758269e-01,\n",
       "         1.44883158e+00],\n",
       "       [-5.25060772e-02, -8.22569778e-01,  7.62758269e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 1.15917263e+00,  3.28414053e-01,  1.21745768e+00,\n",
       "         1.44883158e+00],\n",
       "       [ 1.03800476e+00,  5.58610819e-01,  1.10378283e+00,\n",
       "         1.71209594e+00],\n",
       "       [ 1.03800476e+00, -1.31979479e-01,  8.19595696e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 5.53333275e-01, -1.28296331e+00,  7.05920842e-01,\n",
       "         9.22302838e-01],\n",
       "       [ 7.95669016e-01, -1.31979479e-01,  8.19595696e-01,\n",
       "         1.05393502e+00],\n",
       "       [ 4.32165405e-01,  7.88807586e-01,  9.33270550e-01,\n",
       "         1.44883158e+00],\n",
       "       [ 6.86617933e-02, -1.31979479e-01,  7.62758269e-01,\n",
       "         7.90670654e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab21f01-729f-4056-9fa8-4a21cc5d7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------> Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#------------------> Convert data to PyTorch tensors and move to device\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f40e18-470f-42cf-9c8d-82569ac8a0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------> Define the neural network architecture\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 10\n",
    "output_size = len(set(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d03b70db-7765-4d08-b85e-ca128a1822db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------> Define the neural network\n",
    "fc1 = nn.Linear(input_size, hidden_size)  # Fully connected layer from input to hidde\n",
    "relu = nn.ReLU()  # ReLU activation function\n",
    "fc2 = nn.Linear(hidden_size, output_size)  # Fully connected layer from hidden to output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "762bb957-b293-4428-889f-d4e9e4c5a5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=3, bias=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#------------------> Move neural network to device\n",
    "fc1.to(device)\n",
    "relu.to(device)\n",
    "fc2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb0b1124-5920-479b-8ad9-a2532a6bb7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------> Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Cross Entropy loss for classification\n",
    "optimizer_SGD = optim.SGD([fc1.weight, fc1.bias, fc2.weight, fc2.bias], lr=0.01)  # Stochastic Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebda3178-4a4f-4c15-8abe-c01b9faf30ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adamOptim = torch.optim.Adam([fc1.weight, fc1.bias, fc2.weight, fc2.bias],lr=0.02,betas=(0.9, 0.999), eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "072e0a6b-86cf-43b5-a261-20d2733de3c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_traiwn_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m#----------------> Forward pass\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m relu(fc1(\u001b[43mX_traiwn_tensor\u001b[49m))  \u001b[38;5;66;03m# Input to hidden layer with ReLU activation\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m fc2(hidden)  \u001b[38;5;66;03m# Hidden layer to output\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y_train_tensor)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_traiwn_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#-------------------> Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    #----------------> Forward pass\n",
    "    hidden = relu(fc1(X_traiwn_tensor))  # Input to hidden layer with ReLU activation\n",
    "    outputs = fc2(hidden)  # Hidden layer to output\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    #-----------> Backward pass and optimization\n",
    "    optimizer_SGD.zero_grad()  # Clear gradients\n",
    "    # print(optimizer_SGD)\n",
    "    loss.backward()  # Compute gradients\n",
    "    # print(loss)\n",
    "    optimizer_SGD.step()  # Update weights\n",
    "    # print(optimizer_SGD)\n",
    "\n",
    "\n",
    "    #---------------> Print loss every 100 epochs\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81b60c52-fb5f-40d4-a1c0-4c68283930ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0558, -0.1347,  0.3227,  0.1435],\n",
       "        [ 0.1206, -0.3489,  0.1239,  0.5727],\n",
       "        [ 0.0912, -0.0464, -0.0016, -0.7948],\n",
       "        [-0.5531,  0.1056, -0.5028, -0.0900],\n",
       "        [ 0.4863, -0.4063,  0.7889,  0.9482],\n",
       "        [-0.5914, -0.6224,  0.2575,  0.2730],\n",
       "        [ 0.3640,  0.1728, -0.2416,  0.4699],\n",
       "        [ 0.2282, -0.1675,  0.0057,  0.0733],\n",
       "        [-0.6657,  0.5517, -0.5165, -0.6346],\n",
       "        [-0.1498, -0.5063,  0.3379,  0.6436]], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc3eb7d2-f382-4340-af92-f6c53ed83137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2846, -0.1780,  0.3474,  0.5393, -0.5002, -0.4210, -0.2588,  0.1280,\n",
       "          0.7057, -0.8651],\n",
       "        [-0.3300,  0.0605,  0.4406, -0.1506, -0.2211,  0.2108, -0.0326,  0.1693,\n",
       "         -0.7058,  0.0865],\n",
       "        [-0.0774,  0.5234, -0.8631, -0.2062,  0.9830, -0.2399,  0.0827,  0.0274,\n",
       "         -0.3126,  0.1271]], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2047662c-3f3d-4bf1-968a-e86b1649536c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.2095, -0.2486,  0.8468,  0.2256, -0.1906, -0.1482,  0.0852, -0.2115,\n",
       "         0.0784,  0.5841], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e9ea2d6-782a-4274-929d-5c6c92976d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.1683,  0.7760, -0.0737], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43554235-d903-4cd7-bcf8-4106b4ce54b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "#---------------> Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    hidden = relu(fc1(X_test_tensor))  # Input to hidden layer with ReLU activation\n",
    "    outputs = fc2(hidden)  # Hidden layer to output\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == y_test_tensor).sum().item() / len(y_test_tensor)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ae160b36-a5ab-4ff0-bd4a-1bdc61321d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers : Accuracy\n",
    "# Adadelta : 0.90\n",
    "# Rprop : 0.9333\n",
    "# SGD : 0.9333\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13273ab7-df11-40c1-9a8e-83a5735ba301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7da1407-2492-41e7-a782-8cd1583abd3d",
   "metadata": {},
   "source": [
    "# Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4d8050df-86a0-453a-b158-406597812073",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [torch.randn(10, requires_grad=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6368b07-5974-403e-83de-b659371f23aa",
   "metadata": {},
   "source": [
    "#### Adadelta:\n",
    "##### Advantages:\n",
    "    1. It does not require manual tuning of learning rates.\n",
    "    2. It adapts learning rates per parameter.\n",
    "    3. It has the ability to continue learning with large gradient updates.\n",
    "##### Disadvantages:\n",
    "    1. Computationally expensive due to maintaining per-parameter state.\n",
    "    2. May require more memory compared to simpler optimizers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2202ebb0-9331-46aa-b6ec-d76fc9ac1ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------->  Adaptive Delta optimizer\n",
    "adadelta_params = {\n",
    "    'lr': float,       # learning rate (default: 1.0)\n",
    "    'rho': float,      # decay rate (default: 0.9)\n",
    "    'eps': float,      # term added to the denominator to improve numerical stability (default: 1e-6)\n",
    "    'weight_decay': float,  # weight decay (L2 penalty) (default: 0)\n",
    "}\n",
    "adadelta_optimizer = optim.Adadelta(params, lr=1.0, rho=0.9, eps=1e-6, weight_decay=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51aa9e8-6567-4666-820c-5c0ea268ec01",
   "metadata": {},
   "source": [
    "#### Adagrad:\n",
    "##### Advantages:\n",
    "    1. Automatically adapts learning rates based on the frequency of updates.\n",
    "    2. Suitable for sparse data since it allows individual learning rates per parameter.\n",
    "##### Disadvantages:\n",
    "    1. Learning rates may become too small over time, causing premature convergence.\n",
    "    2. Accumulates squared gradients in the denominator, potentially leading to numerical instabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "efa5e177-58b4-41e1-9e03-2a7349cac275",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------> Adagrad optimizer\n",
    "adagrad_params = {\n",
    "    'lr': float,       # learning rate (default: 0.01)\n",
    "    'lr_decay': float,  # learning rate decay (default: 0)\n",
    "    'weight_decay': float,  # weight decay (L2 penalty) (default: 0)\n",
    "    'initial_accumulator_value': float,  # starting value for the accumulators (default: 0)\n",
    "}\n",
    "adagrad_optimizer = optim.Adagrad(params, lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9eebd9-ac5d-4ccb-9c5b-999c01b60c51",
   "metadata": {},
   "source": [
    "#### Adam:\n",
    "##### Advantages:\n",
    "    1. Combines the advantages of Adagrad and RMSprop.\n",
    "    2. Efficient and effective for a wide range of problems.\n",
    "    3. Maintains separate learning rates per parameter.\n",
    "##### Disadvantages:\n",
    "    1. May converge to suboptimal solutions on certain problems.\n",
    "    2. Requires careful tuning of hyperparameters for optimal performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "96eba649-d66e-4816-967c-4baab40c094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------> Adaptive Moment Estimation optimizer\n",
    "adam_params = {\n",
    "    'lr': float,       # learning rate (default: 0.001)\n",
    "    'betas': tuple,    # coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "    'eps': float,      # term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "    'weight_decay': float,  # weight decay (L2 penalty) (default: 0)\n",
    "    'amsgrad': bool,   # whether to use the AMSGrad variant of this algorithm (default: False)\n",
    "}\n",
    "adam_optimizer = optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, amsgrad=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8c5799-68f5-4f4a-986e-0c360142979f",
   "metadata": {},
   "source": [
    "#### AdamW:\n",
    "##### Advantages:\n",
    "    1. Corrects the weight decay implementation issue present in Adam.\n",
    "    2. Suitable for large-scale training of deep neural networks.\n",
    "##### Disadvantages:\n",
    "    1. Similar to Adam, may require careful hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "333ccbe6-a27d-4b20-b3a8-f6f9c1a41fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------> Adam with Weight Decay optimizer\n",
    "adamw_params = {\n",
    "    'lr': float,       # learning rate (default: 0.001)\n",
    "    'betas': tuple,    # coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "    'eps': float,      # term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "    'weight_decay': float,  # weight decay (L2 penalty) (default: 0)\n",
    "    'amsgrad': bool,   # whether to use the AMSGrad variant of this algorithm (default: False)\n",
    "}\n",
    "adamw_optimizer = optim.AdamW(params, lr=0.001, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, amsgrad=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b55d4d4-a8c7-4f47-a379-112e8e89cf13",
   "metadata": {},
   "source": [
    "#### Adamax:\n",
    "##### Advantages:\n",
    "    1. Simpler update rule compared to Adam.\n",
    "    2. Can converge faster than Adam on some problems.\n",
    "##### Disadvantages:\n",
    "    1. Limited theoretical understanding compared to Adam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "efe7254a-ee78-4263-99d4-94915505c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------> Adam with Infinity Norm optimizer\n",
    "adamax_params = {\n",
    "    'lr': float,       # learning rate (default: 0.002)\n",
    "    'betas': tuple,    # coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "    'eps': float,      # term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "    'weight_decay': float,  # weight decay (L2 penalty) (default: 0)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "adamax_optimizer = optim.Adamax(params, lr=0.002, betas=(0.9, 0.999), eps=1e-8, weight_decay=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601fce16-0a47-4743-8469-9d6a5b26ad9a",
   "metadata": {},
   "source": [
    "#### SparseAdam:\n",
    "##### Advantages:\n",
    "    1. Designed for sparse gradients, making it efficient for sparse data.\n",
    "##### Disadvantages:\n",
    "    1. May not perform optimally on dense data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8b4ad075-9bf5-47e8-a3e1-accf09d72422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------> Sparse Adam optimizer\n",
    "sparseadam_params = {\n",
    "    'lr': float,       # learning rate (default: 0.001)\n",
    "    'betas': tuple,    # coefficients used for computing running averages of gradient and its square (default: (0.9, 0.999))\n",
    "    'eps': float,      # term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "}\n",
    "\n",
    "\n",
    "sparseadam_optimizer = optim.SparseAdam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f75b53-5d50-482b-8430-56471d27186e",
   "metadata": {},
   "source": [
    "#### ASGD:\n",
    "##### Advantages:\n",
    "    1. Suitable for large-scale optimization problems.\n",
    "    2. Provides a good trade-off between convergence speed and memory usage.\n",
    "##### Disadvantages:\n",
    "    1. May require careful tuning of hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4ef42efb-c580-4ee3-8a4d-21dded854828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------> Averaged Stochastic Gradient Descent (ASGD) optimizer\n",
    "asgd_params = {\n",
    "    'lr': float,       # learning rate (default: 0.01)\n",
    "    'lambd': float,    # decay term (default: 1e-4)\n",
    "    'alpha': float,    # power for eta update (default: 0.75)\n",
    "    't0': float,       # point at which to start averaging (default: 1000)\n",
    "    'weight_decay': float,  # weight decay (L2 penalty) (default: 0)\n",
    "}\n",
    "\n",
    "\n",
    "asgd_optimizer = optim.ASGD(params, lr=0.01, lambd=1e-4, alpha=0.75, t0=1000, weight_decay=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a875cd25-e819-4d1b-8bce-24fb44f9cab3",
   "metadata": {},
   "source": [
    "#### LBFGS:\n",
    "##### Advantages:\n",
    "    1. Efficient optimization algorithm for problems with large numbers of parameters.\n",
    "    2. No learning rate to tune.\n",
    "##### Disadvantages:\n",
    "    1. Requires more memory compared to gradient descent-based methods.\n",
    "    2. May not scale well to extremely large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "808f948d-ed34-470d-98de-dd5820126bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------> Limited-memory BFGS optimizer\n",
    "lbfgs_params = {\n",
    "    'lr': float,       # learning rate (default: 1)\n",
    "    'max_iter': int,   # maximal number of iterations (default: 20)\n",
    "    'max_eval': int,   # maximal number of function evaluations (default: max_iter * 1.25)\n",
    "    'tolerance_grad': float,  # termination tolerance on first order optimality (default: 1e-5)\n",
    "    'tolerance_change': float,  # termination tolerance on function value/parameter changes (default: 1e-9)\n",
    "    'history_size': int,  # update history size (default: 100)\n",
    "    'line_search_fn': str,  # the line search function to use (default: None)\n",
    "}\n",
    "\n",
    "\n",
    "lbfgs_optimizer = optim.LBFGS(params, lr=1, max_iter=20, max_eval=None, tolerance_grad=1e-5, tolerance_change=1e-9, history_size=100, line_search_fn=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6c81b-7350-4160-8c61-9442693cb00d",
   "metadata": {},
   "source": [
    "#### RMSprop:\n",
    "##### Advantages:\n",
    "    1. Mitigates the Adagrad's diminishing learning rates issue.\n",
    "    2. Suitable for non-stationary objectives.\n",
    "##### Disadvantages:\n",
    "    1. Requires manual tuning of hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1f18cda2-63c8-4c08-8490-d0730834085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------> Root Mean Square Propagation optimizer\n",
    "rmsprop_params = {\n",
    "    'lr': float,       # learning rate (default: 0.01)\n",
    "    'alpha': float,    # smoothing constant (default: 0.99)\n",
    "    'eps': float,      # term added to the denominator to improve numerical stability (default: 1e-8)\n",
    "    'weight_decay': float,  # weight decay (L2 penalty) (default: 0)\n",
    "    'momentum': float, # momentum factor (default: 0)\n",
    "    'centered': bool,  # whether to compute the centered RMSProp (default: False)\n",
    "}\n",
    "\n",
    "\n",
    "rmsprop_optimizer = optim.RMSprop(params, lr=0.01, alpha=0.99, eps=1e-8, weight_decay=0, momentum=0, centered=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5807a-ff12-43b2-a667-c3003f2a5744",
   "metadata": {},
   "source": [
    "#### Rprop:\n",
    "##### Advantages:\n",
    "    1. Robust to the choice of initial learning rates.\n",
    "    2. Suitable for problems with sparse gradients.\n",
    "##### Disadvantages:\n",
    "    1. May require careful tuning of hyperparameters.\n",
    "    2. Less commonly used compared to other optimizers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9b795242-1c51-42fc-953f-75f7dcdab17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------> Resilient Backpropagation optimizer\n",
    "rprop_params = {\n",
    "    'lr': float,       # learning rate (default: 0.01)\n",
    "    'etas': tuple,     # pair of (etaminus, etaplis), that are multiplicative increase and decrease factors (default: (0.5, 1.2))\n",
    "    'step_sizes': tuple,  # pair of minimal and maximal allowed step sizes (default: (1e-6, 50))\n",
    "}\n",
    "\n",
    "\n",
    "rprop_optimizer = optim.Rprop(params, lr=0.01, etas=(0.5, 1.2), step_sizes=(1e-6, 50))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6e03c1-2c7e-4f27-9731-00f825242266",
   "metadata": {},
   "source": [
    "#### SGD:\n",
    "##### Advantages:\n",
    "    1. Simple and easy to implement.\n",
    "    2. Can be effective with proper tuning and momentum.\n",
    "##### Disadvantages:\n",
    "    1. Prone to getting stuck in local minima or saddle points.\n",
    "    2. Requires careful tuning of learning rates and momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c6795b70-3192-4428-bf4d-4dd49f93afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------> Stochastic Gradient Descent (SGD) optimizer\n",
    "sgd_params = {\n",
    "    'lr': float,       # learning rate (default: 0.01)\n",
    "    'momentum': float, # momentum factor (default: 0)\n",
    "    'dampening': float,  # dampening for momentum (default: 0)\n",
    "    'weight_decay': float,  # weight decay (L2 penalty) (default: 0)\n",
    "    'nesterov': bool,  # enables Nesterov momentum (default: False)\n",
    "}\n",
    "\n",
    "\n",
    "sgd_optimizer = optim.SGD(params, lr=0.01, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef52ba09-401b-4c61-a8e8-42b225bad814",
   "metadata": {},
   "source": [
    "# Cunstome Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1b1f6-c2e8-43f8-9979-612eb1c8ae7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "509f31ac-83c9-42c5-9623-c0056b1b1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Optimizer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c2751e-ac13-4ca4-8cb0-9b6cda5e0a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5c8b58da-a815-4c5b-93d1-68e755dc850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom optimizer\n",
    "class CustomOptimizer(Optimizer):\n",
    "    def __init__(self, params, lr=0.01):\n",
    "        defaults = dict(lr=lr)\n",
    "        super(CustomOptimizer, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                p.data.add_(-group['lr'], grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7c7fe872-a094-4581-8b8f-182bab0b5d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "23dc49fb-ecda-449a-a5d7-c04faaee792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert data to PyTorch tensors and move to device\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "517f78b8-4572-408e-b8f1-9a515fbdb5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the neural network architecture\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 10\n",
    "output_size = len(set(y_train))\n",
    "\n",
    "# Define the neural network\n",
    "fc1 = nn.Linear(input_size, hidden_size)\n",
    "relu = nn.ReLU()\n",
    "fc2 = nn.Linear(hidden_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "084144e5-bd29-4502-a19c-635072864b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Move neural network to device\n",
    "fc1.to(device)\n",
    "relu.to(device)\n",
    "fc2.to(device)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define custom optimizer\n",
    "optimizer_custom = CustomOptimizer([{'params': fc1.parameters()}, {'params': fc2.parameters()}], lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "be29317a-bc8d-4470-a65c-ee099e16835f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.9264\n",
      "Epoch [200/1000], Loss: 0.7235\n",
      "Epoch [300/1000], Loss: 0.6036\n",
      "Epoch [400/1000], Loss: 0.5266\n",
      "Epoch [500/1000], Loss: 0.4732\n",
      "Epoch [600/1000], Loss: 0.4341\n",
      "Epoch [700/1000], Loss: 0.4045\n",
      "Epoch [800/1000], Loss: 0.3805\n",
      "Epoch [900/1000], Loss: 0.3606\n",
      "Epoch [1000/1000], Loss: 0.3426\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    hidden = relu(fc1(X_train_tensor))\n",
    "    outputs = fc2(hidden)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer_custom.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_custom.step()\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "210c4a24-7575-4357-989a-1b4b60d7e051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model on the test set\n",
    "with torch.no_grad():\n",
    "    hidden = relu(fc1(X_test_tensor))\n",
    "    outputs = fc2(hidden)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == y_test_tensor).sum().item() / len(y_test_tensor)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1dda28-e6b0-4b26-94fa-80300c232cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4f6b9b-012f-4f50-9670-b663f9b3b5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
