{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9246a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss = 0.6931471805599453\n",
      "Iteration 100: Loss = 0.4051694686416889\n",
      "Iteration 200: Loss = 0.30000144397943074\n",
      "Iteration 300: Loss = 0.24596597680731574\n",
      "Iteration 400: Loss = 0.21219745516122523\n",
      "Iteration 500: Loss = 0.1885844511983146\n",
      "Iteration 600: Loss = 0.17087513250741104\n",
      "Iteration 700: Loss = 0.15695480583692883\n",
      "Iteration 800: Loss = 0.14564086341127186\n",
      "Iteration 900: Loss = 0.1362130497642862\n",
      "Iteration 0: Loss = 0.6931471805599453\n",
      "Iteration 100: Loss = 0.6548153192275411\n",
      "Iteration 200: Loss = 0.6317616859572815\n",
      "Iteration 300: Loss = 0.6168305899971124\n",
      "Iteration 400: Loss = 0.6066683669528808\n",
      "Iteration 500: Loss = 0.599491200177255\n",
      "Iteration 600: Loss = 0.5942655319054867\n",
      "Iteration 700: Loss = 0.5903582461050394\n",
      "Iteration 800: Loss = 0.5873659724220187\n",
      "Iteration 900: Loss = 0.585023737049958\n",
      "Iteration 0: Loss = 0.6931471805599453\n",
      "Iteration 100: Loss = 0.511246787243923\n",
      "Iteration 200: Loss = 0.44971751713082797\n",
      "Iteration 300: Loss = 0.42152925368154354\n",
      "Iteration 400: Loss = 0.40563952199463243\n",
      "Iteration 500: Loss = 0.39537673054059785\n",
      "Iteration 600: Loss = 0.3881086514515855\n",
      "Iteration 700: Loss = 0.38261957878662245\n",
      "Iteration 800: Loss = 0.3782779457287536\n",
      "Iteration 900: Loss = 0.3747242596264498\n",
      "Test accuracy on iris dataset: 71.11%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def train(self, x, y, alpha=0.01, max_iterations=1000, print_interval=100):\n",
    "        num_samples, num_features = x.shape\n",
    "        self.weights = np.zeros(num_features)\n",
    "\n",
    "        for i in range(max_iterations):\n",
    "            y_pred = self.sigmoid(np.dot(x, self.weights))\n",
    "            error = y_pred - y\n",
    "            gradient = np.dot(x.T, error) / num_samples\n",
    "            self.weights -= alpha * gradient\n",
    "            \n",
    "            if i % print_interval == 0:\n",
    "                loss = -np.mean(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))\n",
    "                print(f\"Iteration {i}: Loss = {loss}\")\n",
    "\n",
    "            if np.all(np.abs(alpha * gradient) < 1e-5):\n",
    "                print(\"Convergence achieved.\")\n",
    "                break\n",
    "\n",
    "    def predict_class(self, x):\n",
    "        if self.weights is None:\n",
    "            print(\"Model not trained yet.\")\n",
    "            return None\n",
    "        y_pred = self.sigmoid(np.dot(x, self.weights))\n",
    "        return np.round(y_pred)\n",
    "\n",
    "    def predict_confidence(self, x):\n",
    "        if self.weights is None:\n",
    "            print(\"Model not trained yet.\")\n",
    "            return None\n",
    "        y_pred = self.sigmoid(np.dot(x, self.weights))\n",
    "        return y_pred\n",
    "\n",
    "    def get_weights(self):\n",
    "        if self.weights is None:\n",
    "            print(\"Model not trained yet.\")\n",
    "            return None\n",
    "        return self.weights\n",
    "\n",
    "def one_vs_all_labels(y, label):\n",
    "    return np.where(y == label, 1, 0)\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train one-vs-all logistic regression for each class\n",
    "models = []\n",
    "for label in np.unique(y):\n",
    "    y_train_ovr = one_vs_all_labels(y_train, label)\n",
    "    model = LogisticRegression()\n",
    "    model.train(X_train, y_train_ovr)\n",
    "    models.append(model)\n",
    "\n",
    "# Predictions and accuracy calculation\n",
    "correct = 0\n",
    "total = len(X_test)\n",
    "for i, x in enumerate(X_test):\n",
    "    predictions = [model.predict_class(x.reshape(1, -1)) for model in models]\n",
    "    predicted_label = np.argmax(predictions)\n",
    "    if predicted_label == y_test[i]:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test accuracy on iris dataset: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059e1128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
